![Lines of code](https://img.shields.io/tokei/lines/github/pacourbet/hta-api?style=plastic)
![GitHub code size in bytes](https://img.shields.io/github/languages/code-size/pacourbet/hta-api)
![GitHub release (latest by date)](https://img.shields.io/github/v/release/pacourbet/hta-api)

# HTA-api â¤ï¸â€ğŸ”¥

ğŸ™‹â€â™‚ï¸

Ce projet est une api qui permet d'assurer un suivi de sa tension artÃ©rielle ğŸ““.
Le backend est dÃ©veloppÃ© avec Django ğŸ Rest Framework et une base de donnÃ©e MySQL.
Le backend et la database sont lancÃ©s dans des containeurs Docker via le `docker-compose.yml`
L'api tourne en local chez moi sur un rapsberry pi. C'est la raison pour laquelle je n'utilise pas une image classique pour le container `MySQL`

## Configuration ğŸ“

### Step 1: crÃ©er un fichier .env avec les donnÃ©es d'environement
> ğŸ”’ `.env` Ã  mettre dans le `.gitignore` pour garder ces data secrÃ¨tes

```
  #.env file
  MYSQL_ROOT_PASSWORD=password
  MYSQL_DATABASE=databaseName
  MYSQL_USER=userName
  MYSQL_PASSWORD=otherPassword
  MYSQL_HOST=dbName
  MYSQL_PORT=portNumber
  DJANGO_SECRET_KEY=secretKey
```

### step 2: lancer le docker-compose

`docker-compose up`

Une fois que le container backend est lancÃ© il faut l'executer en mode interactif pour y effectuer les migrations et crÃ©er l'utilisateur admin de l'application django

`docker container exec -it hta-app_backend_1 bash`

> *Note*:
> Obtenez le nom du containeur django avec `docker container ps`

Une fois dans le containeur:

`python manage.py migrate`

Ensuite on crÃ©Ã© l'admin

`python manage.py createsuperuser`

> Notes:
> - il faut que le mot de passe entrÃ© pour le superuser soit le mÃªme que celui indiquÃ© dans le fichier `.env`
> - dans `docker-compose.yml` changer `hypriot/rapi-mysql` par `ubuntu/mysql` si le systÃ¨me hÃ´te est diffÃ©rent d'un raspberry pi

Peut Ãªtre qu'il faudra relancer le docker-compose une fois la migration effectuÃ©e pour que tout soit fonctionnel:

`docker-compose down`

`docker-compose up`

## Utilisation ğŸš€

Si tout a bien Ã©tÃ© configurÃ©, on devrait avoir une api qui peut interragir avec une base de donnÃ©e sur notre rÃ©seau local. 
Dans mon cas les containeurs tournent sur un raspberry pi, donc il suffit de repÃ©rer l'IP du raspberry pi. On peut ensuite s'y connecter via un navigateur ou avec des commandes comme `curl` comme on le ferait avec n'importe quelle API.

**Exemple**

tapez: `http://IP_LOCAL/api/mesure` dans un navigateur pour visualiser les mesures
ou loggez vous en tant qu'admin via: `http://IP_LOCAL/admin` pour ajouter des valeurs. 

> ğŸ‘‰ IP_LOCAL du type: `192.168.XX.XX` si l'app tourne sur un raspberry pi
> 
> ğŸ‘‰ IP_LOCAL: `127.0.0.1` si l'app tourne sur votre machine

## AmÃ©lioration ğŸ’ª

- L'API tourne sur un rÃ©seau local. On peut imaginer que si nous faisons une mesure et que nous sommes en dehors de notre rÃ©seau local, on sauvegarde cette mesure dans un doc sur Google Drive ğŸ“ par exemple et qu'avec une tÃ¢che rÃ©currente avec Apache Airflow par exemple, l'api du rÃ©seau local vienne rÃ©cupÃ©rer les nouveaux fichiers.
- Ajouter la possibilitÃ© d'ajouter plusieurs mesures d'un coup
- Ajouter un containeur pour interface graphique
